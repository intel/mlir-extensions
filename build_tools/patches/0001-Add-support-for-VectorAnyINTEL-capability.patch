From 94cc2bb6a778cad3b762244d6d78ecf2e19b5372 Mon Sep 17 00:00:00 2001
From: Md Abdullah Shahneous Bari <Md.Abdullah.Shahneous.Bari@intel.com>
Date: Fri, 26 Apr 2024 20:20:28 +0000
Subject: [PATCH 1/7] Add-support-for-VectorAnyINTEL-capability

Allow vector of any lengths between [2-2^63-1].
VectorAnyINTEL capability (part of "SPV_INTEL_vector_compute" extension)
relaxes the length constraint on SPIR-V vector sizes from 2,3, and 4.

Also add support for following:

- Add support for capability inferred extension requirement checking.
If a capability is a requirement, the respective extension that implements
it should also become an extension requirement, there were no support for
that check, as a result, the extension requirement had to be added separately.
This separate requirement addition causes problem when a feature is enabled by
multiple capability, and one of the capability is part of an extension. E.g.,
vector size of 16 can be enabled by both "Vector16" and "vectorAnyINTEL"
capability, however, only "vectorAnyINTEL" has an extension requirement
("SPV_INTEL_vector_compute"). Since the process of adding capability
and extension requirement are independent, there is no way, to handle
cases like this. Therefore, for cases like this, enable adding capability
requirement initially, then do the check for capability inferred extension.

- Add support for optionally skipping capability and extension requirement

---
 .../mlir/Dialect/SPIRV/IR/SPIRVBase.td        |   9 +-
 mlir/include/mlir/IR/CommonTypeConstraints.td |  86 ++++++++++++
 mlir/lib/Dialect/SPIRV/IR/SPIRVDialect.cpp    |   7 +-
 mlir/lib/Dialect/SPIRV/IR/SPIRVTypes.cpp      |  24 +++-
 .../SPIRV/Transforms/SPIRVConversion.cpp      | 132 +++++++++++++++---
 .../arith-to-spirv-unsupported.mlir           |   4 +-
 .../ArithToSPIRV/arith-to-spirv.mlir          |  34 +++++
 .../FuncToSPIRV/types-to-spirv.mlir           |  17 ++-
 .../test/Dialect/SPIRV/IR/arithmetic-ops.mlir |   2 +-
 mlir/test/Dialect/SPIRV/IR/bit-ops.mlir       |   6 +-
 mlir/test/Dialect/SPIRV/IR/gl-ops.mlir        |   2 +-
 mlir/test/Dialect/SPIRV/IR/intel-ext-ops.mlir |   4 +-
 mlir/test/Dialect/SPIRV/IR/logical-ops.mlir   |   2 +-
 .../Dialect/SPIRV/IR/non-uniform-ops.mlir     |  12 +-
 mlir/test/Dialect/SPIRV/IR/ocl-ops.mlir       |  34 ++---
 mlir/test/Target/SPIRV/arithmetic-ops.mlir    |   6 +-
 mlir/test/Target/SPIRV/ocl-ops.mlir           |   6 +
 17 files changed, 319 insertions(+), 68 deletions(-)

diff --git a/mlir/include/mlir/Dialect/SPIRV/IR/SPIRVBase.td b/mlir/include/mlir/Dialect/SPIRV/IR/SPIRVBase.td
index 6ec97e17c5dc..75e42c024553 100644
--- a/mlir/include/mlir/Dialect/SPIRV/IR/SPIRVBase.td
+++ b/mlir/include/mlir/Dialect/SPIRV/IR/SPIRVBase.td
@@ -4138,7 +4138,12 @@ def SPIRV_Int32 : TypeAlias<I32, "Int32">;
 def SPIRV_Float32 : TypeAlias<F32, "Float32">;
 def SPIRV_Float : FloatOfWidths<[16, 32, 64]>;
 def SPIRV_Float16or32 : FloatOfWidths<[16, 32]>;
-def SPIRV_Vector : VectorOfLengthAndType<[2, 3, 4, 8, 16],
+// Remove the vector size restriction
+// Although the vector size can be upto (2^64-1), uint64
+// In tablegen, int is signed int, hence using the upper
+// limit of int64 (2^63-1) rather than uint64, it should serve the purpose
+// for all practical cases
+def SPIRV_Vector : VectorOfLengthRangeAndType<[2, 0x7FFFFFFFFFFFFFFF],
                                        [SPIRV_Bool, SPIRV_Integer, SPIRV_Float]>;
 // Component type check is done in the type parser for the following SPIR-V
 // dialect-specific types so we use "Any" here.
@@ -4189,7 +4194,7 @@ class SPIRV_JointMatrixOfType<list<Type> allowedTypes> :
     "Joint Matrix">;

 class SPIRV_VectorOf<Type type> :
-    VectorOfLengthAndType<[2, 3, 4, 8,16], [type]>;
+    VectorOfLengthRangeAndType<[2, 0x7FFFFFFFFFFFFFFF], [type]>;

 class SPIRV_ScalarOrVectorOf<Type type> :
     AnyTypeOf<[type, SPIRV_VectorOf<type>]>;
diff --git a/mlir/include/mlir/IR/CommonTypeConstraints.td b/mlir/include/mlir/IR/CommonTypeConstraints.td
index af4f13dc0936..28d49d9e91f0 100644
--- a/mlir/include/mlir/IR/CommonTypeConstraints.td
+++ b/mlir/include/mlir/IR/CommonTypeConstraints.td
@@ -608,6 +608,92 @@ class ScalableVectorOfRankAndLengthAndType<list<int> allowedRanks,
   ScalableVectorOfLength<allowedLengths>.summary,
   "::mlir::VectorType">;

+// Whether the number of elements of a vector is from the given
+// `allowedRanges` list, the list has two values, start and end of the range (inclusive)
+class IsVectorOfLengthRangePred<list<int> allowedRanges> :
+  And<[IsVectorTypePred,
+       And<[CPred<[{cast<::mlir::VectorType>($_self).getNumElements()
+                           >= }]
+                         # allowedRanges[0]>,
+                        CPred<[{cast<::mlir::VectorType>($_self).getNumElements()
+                           <= }]
+                         # allowedRanges[1]>]>]>;
+
+// Whether the number of elements of a fixed-length vector is from the given
+// `allowedRanges` list, the list has two values, start and end of the range (inclusive)
+class IsFixedVectorOfLengthRangePred<list<int> allowedRanges> :
+  And<[IsFixedVectorTypePred,
+       And<[CPred<[{cast<::mlir::VectorType>($_self).getNumElements()
+                           >= }]
+                         # allowedRanges[0]>,
+                        CPred<[{cast<::mlir::VectorType>($_self).getNumElements()
+                           <= }]
+                         # allowedRanges[1]>]>]>;
+
+// Whether the number of elements of a scalable vector is from the given
+// `allowedRanges` list, the list has two values, start and end of the range (inclusive)
+class IsScalableVectorOfLengthRangePred<list<int> allowedRanges> :
+  And<[IsVectorTypeWithAnyDimScalablePred,
+       And<[CPred<[{cast<::mlir::VectorType>($_self).getNumElements()
+                           >= }]
+                         # allowedRanges[0]>,
+                        CPred<[{cast<::mlir::VectorType>($_self).getNumElements()
+                           <= }]
+                         # allowedRanges[1]>]>]>;
+
+// Any vector where the number of elements is from the given
+// `allowedRanges` list
+class VectorOfLengthRange<list<int> allowedRanges> : Type<
+  IsVectorOfLengthRangePred<allowedRanges>,
+  " of length " # !interleave(allowedRanges, "-"),
+  "::mlir::VectorType">;
+
+// Any fixed-length vector where the number of elements is from the given
+// `allowedLengths` list
+class FixedVectorOfLengthRange<list<int> allowedRanges> : Type<
+  IsFixedVectorOfLengthRangePred<allowedRanges>,
+  " of length " # !interleave(allowedRanges, "-"),
+  "::mlir::VectorType">;
+
+// Any scalable vector where the number of elements is from the given
+// `allowedLengths` list
+class ScalableVectorOfLengthRange<list<int> allowedRanges> : Type<
+  IsScalableVectorOfLengthRangePred<allowedRanges>,
+  " of length " # !interleave(allowedRanges, "-"),
+  "::mlir::VectorType">;
+
+// Any vector where the number of elements is from the given
+// `allowedRanges` list and the type is from the given `allowedTypes`
+// list
+class VectorOfLengthRangeAndType<list<int> allowedRanges,
+                            list<Type> allowedTypes> : Type<
+  And<[VectorOf<allowedTypes>.predicate,
+       VectorOfLengthRange<allowedRanges>.predicate]>,
+  VectorOf<allowedTypes>.summary # VectorOfLengthRange<allowedRanges>.summary,
+  "::mlir::VectorType">;
+
+// Any fixed-length vector where the number of elements is from the given
+// `allowedRanges` list and the type is from the given `allowedTypes`
+// list
+class FixedVectorOfLengthRangeAndType<list<int> allowedRanges,
+                                    list<Type> allowedTypes> : Type<
+  And<[FixedVectorOf<allowedTypes>.predicate,
+       FixedVectorOfLengthRange<allowedRanges>.predicate]>,
+  FixedVectorOf<allowedTypes>.summary #
+  FixedVectorOfLengthRange<allowedRanges>.summary,
+  "::mlir::VectorType">;
+
+// Any scalable vector where the number of elements is from the given
+// `allowedRanges` list and the type is from the given `allowedTypes`
+// list
+class ScalableVectorOfLengthRangeAndType<list<int> allowedRanges,
+                                    list<Type> allowedTypes> : Type<
+  And<[ScalableVectorOf<allowedTypes>.predicate,
+       ScalableVectorOfLengthRange<allowedRanges>.predicate]>,
+  ScalableVectorOf<allowedTypes>.summary #
+  ScalableVectorOfLengthRange<allowedRanges>.summary,
+  "::mlir::VectorType">;
+
 // Any ShapedType where the size of the n-th dim is contained in `allowedSizes`.
 // Negative values for `n` index in reverse.
 class ShapedTypeWithNthDimOfSize<int n, list<int> allowedSizes> : Type<
diff --git a/mlir/lib/Dialect/SPIRV/IR/SPIRVDialect.cpp b/mlir/lib/Dialect/SPIRV/IR/SPIRVDialect.cpp
index 72488d6e5d0b..b38f20458d32 100644
--- a/mlir/lib/Dialect/SPIRV/IR/SPIRVDialect.cpp
+++ b/mlir/lib/Dialect/SPIRV/IR/SPIRVDialect.cpp
@@ -187,9 +187,12 @@ static Type parseAndVerifyType(SPIRVDialect const &dialect,
       parser.emitError(typeLoc, "only 1-D vector allowed but found ") << t;
       return Type();
     }
-    if (t.getNumElements() > 4) {
+    // Number of elements should be between [2 - 2^63 -1],
+    // since getNumElements() returns an unsigned, the upper limit check is
+    // unnecessary
+    if (t.getNumElements() < 2) {
       parser.emitError(
-          typeLoc, "vector length has to be less than or equal to 4 but found ")
+          typeLoc, "vector length has to be between [2 - 2^63 -1] but found ")
           << t.getNumElements();
       return Type();
     }
diff --git a/mlir/lib/Dialect/SPIRV/IR/SPIRVTypes.cpp b/mlir/lib/Dialect/SPIRV/IR/SPIRVTypes.cpp
index 3f25696aa5eb..2d64fea0dc26 100644
--- a/mlir/lib/Dialect/SPIRV/IR/SPIRVTypes.cpp
+++ b/mlir/lib/Dialect/SPIRV/IR/SPIRVTypes.cpp
@@ -100,9 +100,11 @@ bool CompositeType::classof(Type type) {
 }

 bool CompositeType::isValid(VectorType type) {
-  return type.getRank() == 1 &&
-         llvm::is_contained({2, 3, 4, 8, 16}, type.getNumElements()) &&
-         llvm::isa<ScalarType>(type.getElementType());
+  // Number of elements should be between [2 - 2^63 -1],
+  // since getNumElements() returns an unsigned, the upper limit check is
+  // unnecessary
+  return type.getRank() == 1 && mlir::isa<ScalarType>(type.getElementType()) &&
+         type.getNumElements() >= 2;
 }

 Type CompositeType::getElementType(unsigned index) const {
@@ -170,7 +172,21 @@ void CompositeType::getCapabilities(
       .Case<VectorType>([&](VectorType type) {
         auto vecSize = getNumElements();
         if (vecSize == 8 || vecSize == 16) {
-          static const Capability caps[] = {Capability::Vector16};
+          static const Capability caps[] = {Capability::Vector16,
+                                            Capability::VectorAnyINTEL};
+          ArrayRef<Capability> ref(caps, std::size(caps));
+          capabilities.push_back(ref);
+        }
+        // If the vector size is between (2 - (2^63 - 1))
+        // and not of any size 2, 3, 4, 8, and 16
+        // VectorAnyIntel Capability must be present
+        // for the SPIR-V to be valid
+        llvm::SmallVector<uint32_t, 5> allowedVecRange = {2, 3, 4, 8, 16};
+        if (vecSize >= 2 &&
+            (llvm::none_of(allowedVecRange, [&](uint32_t allowedVecSize) {
+              return vecSize == allowedVecSize;
+            }))) {
+          static const Capability caps[] = {Capability::VectorAnyINTEL};
           ArrayRef<Capability> ref(caps, std::size(caps));
           capabilities.push_back(ref);
         }
diff --git a/mlir/lib/Dialect/SPIRV/Transforms/SPIRVConversion.cpp b/mlir/lib/Dialect/SPIRV/Transforms/SPIRVConversion.cpp
index 4072608dc8f8..3fc675632970 100644
--- a/mlir/lib/Dialect/SPIRV/Transforms/SPIRVConversion.cpp
+++ b/mlir/lib/Dialect/SPIRV/Transforms/SPIRVConversion.cpp
@@ -43,9 +43,13 @@ using namespace mlir;
 template <typename LabelT>
 static LogicalResult checkExtensionRequirements(
     LabelT label, const spirv::TargetEnv &targetEnv,
-    const spirv::SPIRVType::ExtensionArrayRefVector &candidates) {
+    const spirv::SPIRVType::ExtensionArrayRefVector &candidates,
+    const ArrayRef<spirv::Extension> &elidedCandidates = {}) {
   for (const auto &ors : candidates) {
-    if (targetEnv.allows(ors))
+    if (targetEnv.allows(ors) ||
+        llvm::any_of(elidedCandidates, [&](spirv::Extension elidedExt) {
+          return llvm::is_contained(ors, elidedExt);
+        }))
       continue;

     LLVM_DEBUG({
@@ -71,9 +75,13 @@ static LogicalResult checkExtensionRequirements(
 template <typename LabelT>
 static LogicalResult checkCapabilityRequirements(
     LabelT label, const spirv::TargetEnv &targetEnv,
-    const spirv::SPIRVType::CapabilityArrayRefVector &candidates) {
+    const spirv::SPIRVType::CapabilityArrayRefVector &candidates,
+    const ArrayRef<spirv::Capability> &elidedCandidates = {}) {
   for (const auto &ors : candidates) {
-    if (targetEnv.allows(ors))
+    if (targetEnv.allows(ors) ||
+        llvm::any_of(elidedCandidates, [&](spirv::Capability elidedCap) {
+          return llvm::is_contained(ors, elidedCap);
+        }))
       continue;

     LLVM_DEBUG({
@@ -90,6 +98,55 @@ static LogicalResult checkCapabilityRequirements(
   return success();
 }

+/// Check capabilities and extensions requirements,
+/// this function also checks for capability infered extension requirements,
+/// the check is based on capabilities that are passed to the targetEnv.
+///
+/// It Also provides a way to relax requirements for certain capabilities and
+/// extensions (e.g., elidedCapCandidates, elidedExtCandidates), this is to
+/// allow passes to relax certain requirements based on an option (e.g.,
+/// relaxing bitwidth requirement, see convertScalarType(), ConvertVectorType())
+template <typename LabelT>
+static LogicalResult checkCapabilityAndExtensionRequirements(
+    LabelT label, const spirv::TargetEnv &targetEnv,
+    const spirv::SPIRVType::CapabilityArrayRefVector &capCandidates,
+    const spirv::SPIRVType::ExtensionArrayRefVector &extCandidates,
+    const ArrayRef<spirv::Capability> &elidedCapCandidates = {},
+    const ArrayRef<spirv::Extension> &elidedExtCandidates = {}) {
+  llvm::SmallVector<::llvm::ArrayRef<::mlir::spirv::Extension>, 8>
+      updatedExtCandidates;
+  llvm::copy(extCandidates, updatedExtCandidates.begin());
+  if (failed(checkCapabilityRequirements(label, targetEnv, capCandidates,
+                                         elidedCapCandidates)))
+    return failure();
+  // Add capablity infered extensions to the list of extension requirement list,
+  // only considers the capabilities that already available in the targetEnv
+
+  // @FIXME: Some capabilities are part of both the core SPIR-V specification
+  // and an extension (e.g., 'Groups' capability is part of both core
+  // specification and SPV_AMD_shader_ballot extension, hence we should relax
+  // the capability inferred extension for this cases)
+  static const ::mlir::spirv::Capability multiModalCaps[] = {
+      ::mlir::spirv::Capability::Groups};
+  ArrayRef<::mlir::spirv::Capability> multiModalCapsArrayRef(
+      multiModalCaps, std::size(multiModalCaps));
+
+  for (auto cap : targetEnv.getAttr().getCapabilities()) {
+    if (llvm::any_of(
+            multiModalCapsArrayRef,
+            [&](::mlir::spirv::Capability mMCap) { return cap == mMCap; }))
+      continue;
+    std::optional<::llvm::ArrayRef<::mlir::spirv::Extension>> ext =
+        getExtensions(cap);
+    if (ext.has_value())
+      updatedExtCandidates.push_back(ext.value());
+  }
+  if (failed(checkExtensionRequirements(label, targetEnv, updatedExtCandidates,
+                                        elidedExtCandidates)))
+    return failure();
+  return success();
+}
+
 /// Returns true if the given `storageClass` needs explicit layout when used in
 /// Shader environments.
 static bool needsExplicitLayout(spirv::StorageClass storageClass) {
@@ -247,12 +304,17 @@ convertScalarType(const spirv::TargetEnv &targetEnv,
     return nullptr;
   }

-  if (auto floatType = dyn_cast<FloatType>(type)) {
+  //if (auto floatType = dyn_cast<FloatType>(type)) {
+  // Convert to 32-bit float and remove floatType related capability
+  // restriction
+  if (auto floatType = dyn_cast<FloatType>(type)) {
     LLVM_DEBUG(llvm::dbgs() << type << " converted to 32-bit for SPIR-V\n");
     return Builder(targetEnv.getContext()).getF32Type();
   }

-  auto intType = cast<IntegerType>(type);
+  //auto intType = cast<IntegerType>(type);
+  // Convert to 32-bit int and remove intType related capability restriction
+  auto intType = cast<IntegerType>(type);
   LLVM_DEBUG(llvm::dbgs() << type << " converted to 32-bit for SPIR-V\n");
   return IntegerType::get(targetEnv.getContext(), /*width=*/32,
                           intType.getSignedness());
@@ -342,16 +404,40 @@ convertVectorType(const spirv::TargetEnv &targetEnv,
   cast<spirv::CompositeType>(type).getExtensions(extensions, storageClass);
   cast<spirv::CompositeType>(type).getCapabilities(capabilities, storageClass);

-  // If all requirements are met, then we can accept this type as-is.
-  if (succeeded(checkCapabilityRequirements(type, targetEnv, capabilities)) &&
-      succeeded(checkExtensionRequirements(type, targetEnv, extensions)))
-    return type;
-
+  // If the bit-width related capabilities and extensions are not met
+  // for lower bit-width (<32-bit), convert it to 32-bit
   auto elementType =
       convertScalarType(targetEnv, options, scalarType, storageClass);
   if (elementType)
-    return VectorType::get(type.getShape(), elementType);
-  return nullptr;
+    type = VectorType::get(type.getShape(), elementType);
+  else
+    return nullptr;
+
+  llvm::SmallVector<spirv::Capability, 4> elidedCaps;
+  llvm::SmallVector<spirv::Extension, 4> elidedExts;
+
+  // Relax the bitwidth requirements for capabilities and extensions
+  if (options.emulateLT32BitScalarTypes) {
+    elidedCaps.push_back(spirv::Capability::Int8);
+    elidedCaps.push_back(spirv::Capability::Int16);
+    elidedCaps.push_back(spirv::Capability::Float16);
+  }
+  // For capabilities whose requirements were relaxed, relax requirements for
+  // the extensions that were infered by those capabilities (e.g., elidedCaps)
+  for (auto cap : elidedCaps) {
+    std::optional<::llvm::ArrayRef<::mlir::spirv::Extension>> ext =
+        mlir::spirv::getExtensions(cap);
+    if (ext.has_value())
+      elidedExts.insert(elidedExts.end(), ext.value().begin(),
+                        ext.value().end());
+  }
+  // If all requirements are met, then we can accept this type as-is.
+  if (succeeded(checkCapabilityAndExtensionRequirements(
+          type, targetEnv, capabilities, extensions, elidedCaps, elidedExts)))
+    return type;
+  else {
+    return nullptr;
+  }
 }

 static Type
@@ -1163,16 +1249,18 @@ bool SPIRVConversionTarget::isLegalOp(Operation *op) {
   SmallVector<ArrayRef<spirv::Extension>, 4> typeExtensions;
   SmallVector<ArrayRef<spirv::Capability>, 8> typeCapabilities;
   for (Type valueType : valueTypes) {
-    typeExtensions.clear();
-    cast<spirv::SPIRVType>(valueType).getExtensions(typeExtensions);
-    if (failed(checkExtensionRequirements(op->getName(), this->targetEnv,
-                                          typeExtensions)))
-      return false;
-
     typeCapabilities.clear();
-    cast<spirv::SPIRVType>(valueType).getCapabilities(typeCapabilities);
-    if (failed(checkCapabilityRequirements(op->getName(), this->targetEnv,
-                                           typeCapabilities)))
+    cast<spirv::SPIRVType>(valueType).getCapabilities(typeCapabilities);
+    typeExtensions.clear();
+    cast<spirv::SPIRVType>(valueType).getExtensions(typeExtensions);
+    // Checking for capability and extension requirements along with capability
+    // infered extensions
+    // If a capability is present, the extension that
+    // supports it should also be present, this reduces the burden of adding
+    // extension requirement that may or maynot be added in
+    // CompositeType::getExtensions()
+    if (failed(checkCapabilityAndExtensionRequirements(
+            op->getName(), this->targetEnv, typeCapabilities, typeExtensions)))
       return false;
   }

diff --git a/mlir/test/Conversion/ArithToSPIRV/arith-to-spirv-unsupported.mlir b/mlir/test/Conversion/ArithToSPIRV/arith-to-spirv-unsupported.mlir
index 0d92a8e676d8..d61ace8d6876 100644
--- a/mlir/test/Conversion/ArithToSPIRV/arith-to-spirv-unsupported.mlir
+++ b/mlir/test/Conversion/ArithToSPIRV/arith-to-spirv-unsupported.mlir
@@ -11,9 +11,9 @@ module attributes {
     #spirv.vce<v1.0, [Int8, Int16, Int64, Float16, Float64, Shader], []>, #spirv.resource_limits<>>
 } {

-func.func @unsupported_5elem_vector(%arg0: vector<5xi32>) {
+func.func @unsupported_5elem_vector(%arg0: vector<5xi32>, %arg1: vector<5xi32>) {
   // expected-error@+1 {{failed to legalize operation 'arith.subi'}}
-  %1 = arith.subi %arg0, %arg0: vector<5xi32>
+  %1 = arith.subi %arg0, %arg1: vector<5xi32>
   return
 }

diff --git a/mlir/test/Conversion/ArithToSPIRV/arith-to-spirv.mlir b/mlir/test/Conversion/ArithToSPIRV/arith-to-spirv.mlir
index ae47ae36ca51..644996fe0fa7 100644
--- a/mlir/test/Conversion/ArithToSPIRV/arith-to-spirv.mlir
+++ b/mlir/test/Conversion/ArithToSPIRV/arith-to-spirv.mlir
@@ -1447,6 +1447,40 @@ func.func @ops_flags(%arg0: i64, %arg1: i64) {
   %2 = arith.muli %arg0, %arg1 overflow<nsw, nuw> : i64
   // CHECK: %{{.*}} = spirv.IMul %{{.*}}, %{{.*}} : i64
   %3 = arith.muli %arg0, %arg1 overflow<nsw, nuw> : i64
+
+  return
+}
+
+
+} // end module
+
+// -----
+
+//===----------------------------------------------------------------------===//
+// VectorAnyINTEL support
+//===----------------------------------------------------------------------===//
+
+// Check that with VectorAnyINTEL, VectorComputeINTEL capability,
+// and SPV_INTEL_vector_compute extension, any sized (2-2^63 -1) vector is allowed
+module attributes {
+  spirv.target_env = #spirv.target_env<
+    #spirv.vce<v1.0, [Int8, Int16, Int64, Float16, Float64, Kernel, VectorAnyINTEL], [SPV_INTEL_vector_compute]>, #spirv.resource_limits<>>
+} {
+
+// CHECK-LABEL: @any_vector
+func.func @any_vector(%arg0: vector<16xi32>, %arg1: vector<16xi32>) {
+  // CHECK: spirv.ISub %{{.+}}, %{{.+}}: vector<16xi32>
+  %0 = arith.subi %arg0, %arg1: vector<16xi32>
+  return
+}
+
+// Check float vector types of any size.
+// CHECK-LABEL: @float_vector58
+func.func @float_vector58(%arg0: vector<5xf16>, %arg1: vector<8xf64>) {
+  // CHECK: spirv.FAdd %{{.*}}, %{{.*}}: vector<5xf16>
+  %0 = arith.addf %arg0, %arg0: vector<5xf16>
+  // CHECK: spirv.FMul %{{.*}}, %{{.*}}: vector<8xf64>
+  %1 = arith.mulf %arg1, %arg1: vector<8xf64>
   return
 }

diff --git a/mlir/test/Conversion/FuncToSPIRV/types-to-spirv.mlir b/mlir/test/Conversion/FuncToSPIRV/types-to-spirv.mlir
index 82d750755ffe..6f364c5b0875 100644
--- a/mlir/test/Conversion/FuncToSPIRV/types-to-spirv.mlir
+++ b/mlir/test/Conversion/FuncToSPIRV/types-to-spirv.mlir
@@ -351,8 +351,21 @@ module attributes {
   spirv.target_env = #spirv.target_env<#spirv.vce<v1.0, [], []>, #spirv.resource_limits<>>
 } {

-// CHECK-NOT: spirv.func @large_vector
-func.func @large_vector(%arg0: vector<1024xi32>) { return }
+// CHECK-NOT: spirv.func @large_vector_unsupported
+func.func @large_vector_unsupported(%arg0: vector<1024xi32>) { return }
+
+} // end module
+
+
+// -----
+
+// Check that large vectors are supported with VectorAnyINTEL or VectorComputeINTEL.
+module attributes {
+  spirv.target_env = #spirv.target_env<#spirv.vce<v1.0, [Float16, Kernel, VectorAnyINTEL], [SPV_INTEL_vector_compute]>, #spirv.resource_limits<>>
+} {
+
+// CHECK: spirv.func @large_any_vector
+func.func @large_any_vector(%arg0: vector<1024xi32>) { return }

 } // end module

diff --git a/mlir/test/Dialect/SPIRV/IR/arithmetic-ops.mlir b/mlir/test/Dialect/SPIRV/IR/arithmetic-ops.mlir
index 2d0c86e08de5..61fc0b53ed26 100644
--- a/mlir/test/Dialect/SPIRV/IR/arithmetic-ops.mlir
+++ b/mlir/test/Dialect/SPIRV/IR/arithmetic-ops.mlir
@@ -283,7 +283,7 @@ func.func @dot(%arg0: vector<4xf32>, %arg1: vector<4xf32>) -> f16 {
 // -----

 func.func @dot(%arg0: vector<4xi32>, %arg1: vector<4xi32>) -> i32 {
-  // expected-error @+1 {{'spirv.Dot' op operand #0 must be vector of 16/32/64-bit float values of length 2/3/4/8/16}}
+  // expected-error @+1 {{op operand #0 must be vector of 16/32/64-bit float values of length 2-9223372036854775807, but got 'vector<4xi32>'}}
   %0 = spirv.Dot %arg0, %arg1 : vector<4xi32> -> i32
   return %0 : i32
 }
diff --git a/mlir/test/Dialect/SPIRV/IR/bit-ops.mlir b/mlir/test/Dialect/SPIRV/IR/bit-ops.mlir
index f3f0ebf60f46..2994b00d582c 100644
--- a/mlir/test/Dialect/SPIRV/IR/bit-ops.mlir
+++ b/mlir/test/Dialect/SPIRV/IR/bit-ops.mlir
@@ -137,7 +137,7 @@ func.func @bitwise_or_all_ones_vector(%arg: vector<3xi8>) -> vector<3xi8> {
 // -----

 func.func @bitwise_or_float(%arg0: f16, %arg1: f16) -> f16 {
-  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2/3/4}}
+  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2-9223372036854775807}}
   %0 = spirv.BitwiseOr %arg0, %arg1 : f16
   return %0 : f16
 }
@@ -165,7 +165,7 @@ func.func @bitwise_xor_vector(%arg: vector<4xi32>) -> vector<4xi32> {
 // -----

 func.func @bitwise_xor_float(%arg0: f16, %arg1: f16) -> f16 {
-  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2/3/4}}
+  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2-9223372036854775807}}
   %0 = spirv.BitwiseXor %arg0, %arg1 : f16
   return %0 : f16
 }
@@ -274,7 +274,7 @@ func.func @bitwise_and_zext_vector(%arg: vector<2xi8>) -> vector<2xi32> {
 // -----

 func.func @bitwise_and_float(%arg0: f16, %arg1: f16) -> f16 {
-  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2/3/4}}
+  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2-9223372036854775807}}
   %0 = spirv.BitwiseAnd %arg0, %arg1 : f16
   return %0 : f16
 }
diff --git a/mlir/test/Dialect/SPIRV/IR/gl-ops.mlir b/mlir/test/Dialect/SPIRV/IR/gl-ops.mlir
index 3683e5b469b1..a95a6001fd20 100644
--- a/mlir/test/Dialect/SPIRV/IR/gl-ops.mlir
+++ b/mlir/test/Dialect/SPIRV/IR/gl-ops.mlir
@@ -27,7 +27,7 @@ func.func @exp(%arg0 : i32) -> () {
 // -----

 func.func @exp(%arg0 : vector<5xf32>) -> () {
-  // expected-error @+1 {{op operand #0 must be 16/32-bit float or vector of 16/32-bit float values of length 2/3/4}}
+  // CHECK: spirv.GL.Exp {{%.*}} : vector<5xf32
   %2 = spirv.GL.Exp %arg0 : vector<5xf32>
   return
 }
diff --git a/mlir/test/Dialect/SPIRV/IR/intel-ext-ops.mlir b/mlir/test/Dialect/SPIRV/IR/intel-ext-ops.mlir
index 53a1015de75b..6970b8ec0628 100644
--- a/mlir/test/Dialect/SPIRV/IR/intel-ext-ops.mlir
+++ b/mlir/test/Dialect/SPIRV/IR/intel-ext-ops.mlir
@@ -21,7 +21,7 @@ spirv.func @f32_to_bf16_vec(%arg0 : vector<2xf32>) "None" {
 // -----

 spirv.func @f32_to_bf16_unsupported(%arg0 : f64) "None" {
-  // expected-error @+1 {{operand #0 must be Float32 or vector of Float32 values of length 2/3/4/8/16, but got}}
+  // expected-error @+1 {{op operand #0 must be Float32 or vector of Float32 values of length 2-9223372036854775807, but got 'f64'}}
   %0 = spirv.INTEL.ConvertFToBF16 %arg0 : f64 to i16
   spirv.Return
 }
@@ -57,7 +57,7 @@ spirv.func @bf16_to_f32_vec(%arg0 : vector<2xi16>) "None" {
 // -----

 spirv.func @bf16_to_f32_unsupported(%arg0 : i16) "None" {
-  // expected-error @+1 {{result #0 must be Float32 or vector of Float32 values of length 2/3/4/8/16, but got}}
+  // expected-error @+1 {{op result #0 must be Float32 or vector of Float32 values of length 2-9223372036854775807, but got 'f16'}}
   %0 = spirv.INTEL.ConvertBF16ToF %arg0 : i16 to f16
   spirv.Return
 }
diff --git a/mlir/test/Dialect/SPIRV/IR/logical-ops.mlir b/mlir/test/Dialect/SPIRV/IR/logical-ops.mlir
index 7dc0bd99f54b..5dd9901828cd 100644
--- a/mlir/test/Dialect/SPIRV/IR/logical-ops.mlir
+++ b/mlir/test/Dialect/SPIRV/IR/logical-ops.mlir
@@ -166,7 +166,7 @@ func.func @logicalUnary(%arg0 : i1)

 func.func @logicalUnary(%arg0 : i32)
 {
-  // expected-error @+1 {{'operand' must be bool or vector of bool values of length 2/3/4/8/16, but got 'i32'}}
+  // expected-error @+1 {{'operand' must be bool or vector of bool values of length 2-9223372036854775807, but got 'i32'}}
   %0 = spirv.LogicalNot %arg0 : i32
   return
 }
diff --git a/mlir/test/Dialect/SPIRV/IR/non-uniform-ops.mlir b/mlir/test/Dialect/SPIRV/IR/non-uniform-ops.mlir
index f7fd05b36bae..5228bb719d94 100644
--- a/mlir/test/Dialect/SPIRV/IR/non-uniform-ops.mlir
+++ b/mlir/test/Dialect/SPIRV/IR/non-uniform-ops.mlir
@@ -439,7 +439,7 @@ func.func @group_non_uniform_bitwise_and(%val: i32) -> i32 {
 // -----

 func.func @group_non_uniform_bitwise_and(%val: i1) -> i1 {
-  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2/3/4/8/16, but got 'i1'}}
+  // expected-error @+1 {{op operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2-9223372036854775807, but got 'i1'}}
   %0 = spirv.GroupNonUniformBitwiseAnd "Workgroup" "Reduce" %val : i1
   return %0: i1
 }
@@ -460,7 +460,7 @@ func.func @group_non_uniform_bitwise_or(%val: i32) -> i32 {
 // -----

 func.func @group_non_uniform_bitwise_or(%val: i1) -> i1 {
-  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2/3/4/8/16, but got 'i1'}}
+  // expected-error @+1 {{op operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2-9223372036854775807, but got 'i1'}}
   %0 = spirv.GroupNonUniformBitwiseOr "Workgroup" "Reduce" %val : i1
   return %0: i1
 }
@@ -481,7 +481,7 @@ func.func @group_non_uniform_bitwise_xor(%val: i32) -> i32 {
 // -----

 func.func @group_non_uniform_bitwise_xor(%val: i1) -> i1 {
-  // expected-error @+1 {{operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2/3/4/8/16, but got 'i1'}}
+  // expected-error @+1 {{op operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2-9223372036854775807, but got 'i1'}}
   %0 = spirv.GroupNonUniformBitwiseXor "Workgroup" "Reduce" %val : i1
   return %0: i1
 }
@@ -502,7 +502,7 @@ func.func @group_non_uniform_logical_and(%val: i1) -> i1 {
 // -----

 func.func @group_non_uniform_logical_and(%val: i32) -> i32 {
-  // expected-error @+1 {{operand #0 must be bool or vector of bool values of length 2/3/4/8/16, but got 'i32'}}
+  // expected-error @+1 {{op operand #0 must be bool or vector of bool values of length 2-9223372036854775807, but got 'i32'}}
   %0 = spirv.GroupNonUniformLogicalAnd "Workgroup" "Reduce" %val : i32
   return %0: i32
 }
@@ -523,7 +523,7 @@ func.func @group_non_uniform_logical_or(%val: i1) -> i1 {
 // -----

 func.func @group_non_uniform_logical_or(%val: i32) -> i32 {
-  // expected-error @+1 {{operand #0 must be bool or vector of bool values of length 2/3/4/8/16, but got 'i32'}}
+  // expected-error @+1 {{op operand #0 must be bool or vector of bool values of length 2-9223372036854775807, but got 'i32'}}
   %0 = spirv.GroupNonUniformLogicalOr "Workgroup" "Reduce" %val : i32
   return %0: i32
 }
@@ -544,7 +544,7 @@ func.func @group_non_uniform_logical_xor(%val: i1) -> i1 {
 // -----

 func.func @group_non_uniform_logical_xor(%val: i32) -> i32 {
-  // expected-error @+1 {{operand #0 must be bool or vector of bool values of length 2/3/4/8/16, but got 'i32'}}
+  // expected-error @+1 {{op operand #0 must be bool or vector of bool values of length 2-9223372036854775807, but got 'i32'}}
   %0 = spirv.GroupNonUniformLogicalXor "Workgroup" "Reduce" %val : i32
   return %0: i32
 }
diff --git a/mlir/test/Dialect/SPIRV/IR/ocl-ops.mlir b/mlir/test/Dialect/SPIRV/IR/ocl-ops.mlir
index 81ba471d3f51..7a29abd44b34 100644
--- a/mlir/test/Dialect/SPIRV/IR/ocl-ops.mlir
+++ b/mlir/test/Dialect/SPIRV/IR/ocl-ops.mlir
@@ -27,7 +27,7 @@ func.func @exp(%arg0 : i32) -> () {
 // -----

 func.func @exp(%arg0 : vector<5xf32>) -> () {
-  // expected-error @+1 {{op operand #0 must be 16/32/64-bit float or vector of 16/32/64-bit float values of length 2/3/4}}
+  // CHECK: spirv.CL.exp {{%.*}} : vector<5xf32>
   %2 = spirv.CL.exp %arg0 : vector<5xf32>
   return
 }
@@ -66,6 +66,14 @@ func.func @fabsvec(%arg0 : vector<3xf16>) -> () {
   return
 }

+// -----
+
+func.func @fabs_any_vec(%arg0 : vector<5xf32>) -> () {
+  // CHECK: spirv.CL.fabs {{%.*}} : vector<5xf32>
+  %2 = spirv.CL.fabs %arg0 : vector<5xf32>
+  return
+}
+
 func.func @fabsf64(%arg0 : f64) -> () {
   // CHECK: spirv.CL.fabs {{%.*}} : f64
   %2 = spirv.CL.fabs %arg0 : f64
@@ -82,14 +90,6 @@ func.func @fabs(%arg0 : i32) -> () {

 // -----

-func.func @fabs(%arg0 : vector<5xf32>) -> () {
-  // expected-error @+1 {{op operand #0 must be 16/32/64-bit float or vector of 16/32/64-bit float values of length 2/3/4}}
-  %2 = spirv.CL.fabs %arg0 : vector<5xf32>
-  return
-}
-
-// -----
-
 func.func @fabs(%arg0 : f32, %arg1 : f32) -> () {
   // expected-error @+1 {{expected ':'}}
   %2 = spirv.CL.fabs %arg0, %arg1 : i32
@@ -122,6 +122,14 @@ func.func @sabsvec(%arg0 : vector<3xi16>) -> () {
   return
 }

+// -----
+
+func.func @sabs_any_vec(%arg0 : vector<5xi32>) -> () {
+  // CHECK: spirv.CL.s_abs {{%.*}} : vector<5xi32>
+  %2 = spirv.CL.s_abs %arg0 : vector<5xi32>
+  return
+}
+
 func.func @sabsi64(%arg0 : i64) -> () {
   // CHECK: spirv.CL.s_abs {{%.*}} : i64
   %2 = spirv.CL.s_abs %arg0 : i64
@@ -144,14 +152,6 @@ func.func @sabs(%arg0 : f32) -> () {

 // -----

-func.func @sabs(%arg0 : vector<5xi32>) -> () {
-  // expected-error @+1 {{op operand #0 must be 8/16/32/64-bit integer or vector of 8/16/32/64-bit integer values of length 2/3/4}}
-  %2 = spirv.CL.s_abs %arg0 : vector<5xi32>
-  return
-}
-
-// -----
-
 func.func @sabs(%arg0 : i32, %arg1 : i32) -> () {
   // expected-error @+1 {{expected ':'}}
   %2 = spirv.CL.s_abs %arg0, %arg1 : i32
diff --git a/mlir/test/Target/SPIRV/arithmetic-ops.mlir b/mlir/test/Target/SPIRV/arithmetic-ops.mlir
index b1ea13c6854f..90144afc6f3a 100644
--- a/mlir/test/Target/SPIRV/arithmetic-ops.mlir
+++ b/mlir/test/Target/SPIRV/arithmetic-ops.mlir
@@ -6,9 +6,9 @@ spirv.module Logical GLSL450 requires #spirv.vce<v1.0, [Shader], []> {
     %0 = spirv.FMul %arg0, %arg1 : f32
     spirv.Return
   }
-  spirv.func @fadd(%arg0 : vector<4xf32>, %arg1 : vector<4xf32>) "None" {
-    // CHECK: {{%.*}} = spirv.FAdd {{%.*}}, {{%.*}} : vector<4xf32>
-    %0 = spirv.FAdd %arg0, %arg1 : vector<4xf32>
+  spirv.func @fadd(%arg0 : vector<5xf32>, %arg1 : vector<5xf32>) "None" {
+    // CHECK: {{%.*}} = spirv.FAdd {{%.*}}, {{%.*}} : vector<5xf32>
+    %0 = spirv.FAdd %arg0, %arg1 : vector<5xf32>
     spirv.Return
   }
   spirv.func @fdiv(%arg0 : vector<4xf32>, %arg1 : vector<4xf32>) "None" {
diff --git a/mlir/test/Target/SPIRV/ocl-ops.mlir b/mlir/test/Target/SPIRV/ocl-ops.mlir
index 9a2e4cf62e37..31a7f616d648 100644
--- a/mlir/test/Target/SPIRV/ocl-ops.mlir
+++ b/mlir/test/Target/SPIRV/ocl-ops.mlir
@@ -39,6 +39,12 @@ spirv.module Physical64 OpenCL requires #spirv.vce<v1.0, [Kernel, Addresses], []
     spirv.Return
   }

+  spirv.func @vector_anysize(%arg0 : vector<5000xf32>) "None" {
+    // CHECK: {{%.*}} = spirv.CL.fabs {{%.*}} : vector<5000xf32>
+    %0 = spirv.CL.fabs %arg0 : vector<5000xf32>
+    spirv.Return
+  }
+
   spirv.func @fma(%arg0 : f32, %arg1 : f32, %arg2 : f32) "None" {
     // CHECK: spirv.CL.fma {{%[^,]*}}, {{%[^,]*}}, {{%[^,]*}} : f32
     %13 = spirv.CL.fma %arg0, %arg1, %arg2 : f32
--
2.34.1
